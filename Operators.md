# ‚úàÔ∏è Operadores no Apache Airflow

Os **operadores** s√£o **classes do Python** que encapsulam a l√≥gica necess√°ria para executar **uma unidade de trabalho (tarefa)**. Eles definem as **a√ß√µes a serem realizadas** por uma tarefa, abstraindo grande parte do c√≥digo que seria necess√°rio escrever manualmente.

Ao instanciar um operador com os par√¢metros apropriados, essa inst√¢ncia **se torna uma tarefa execut√°vel** dentro de um DAG (Directed Acyclic Graph).

---

## üîß Tipos Comuns de Operadores

O Airflow possui uma ampla variedade de operadores prontos para uso. Abaixo est√£o alguns dos mais utilizados:

| Operador              | Descri√ß√£o                                                                 |
|-----------------------|---------------------------------------------------------------------------|
| `PythonOperator`      | Executa uma **fun√ß√£o Python**.                                            |
| `BashOperator`        | Executa um **comando ou script Bash**.                                    |
| `KubernetesPodOperator` | Executa uma **imagem Docker em um pod do Kubernetes**.                 |
| `SnowflakeOperator`   | Executa uma **consulta no banco de dados Snowflake**.                    |
| `EmailOperator`       | Envia um **e-mail**.                                                      |

> üí° **Dica:** Se n√£o houver um operador adequado para seu caso de uso, o Airflow permite **criar operadores personalizados**.

---

## üéØ Caracter√≠sticas de um Operador

Todo operador no Airflow deve seguir tr√™s princ√≠pios fundamentais:

1. **Idempot√™ncia**  
   > A tarefa deve produzir sempre o **mesmo resultado**, mesmo que seja executada m√∫ltiplas vezes com os **mesmos par√¢metros**.

2. **Isolamento**  
   > A tarefa deve ser **independente**, sem **compartilhar recursos** com outras tarefas ou operadores.

3. **Atomicidade**  
   > A tarefa deve ser uma **unidade indivis√≠vel** de trabalho: ou ela √© executada por completo, ou **n√£o √© executada**.

---

## üìå Conclus√£o

Operadores s√£o **blocos fundamentais** no Airflow, tornando-o uma ferramenta poderosa para orquestra√ß√£o de dados. Com eles, √© poss√≠vel realizar tarefas complexas com **menos c√≥digo** e maior **clareza na manuten√ß√£o** dos fluxos de trabalho.

Mais sobre
https://airflow.apache.org/docs/apache-airflow/2.3.2/concepts/operators.html



---

## Variaveis Dinamicas

O Airflow utiliza o Jinja, uma estrutura de modelagem em Python, como seu mecanismo de modelagem. Vamos conhecer mais algumas vari√°veis que podemos utilizar em tempo de execu√ß√£o:

data_interval_start: data do in√≠cio do intervalo de dados;
data_interval_end: data do fim do intervalo de dados;
ds: data l√≥gica de execu√ß√£o do DAG;
ds_nodash: data l√≥gica de execu√ß√£o do DAG sem nenhuma separa√ß√£o por tra√ßos.
O Airflow inclui muitas outras vari√°veis ‚Äã‚Äãque podem ser usadas para modelagem. Caso queira conhec√™-las, consulte a documenta√ß√£o:

https://airflow.apache.org/docs/apache-airflow/2.3.2/templates-ref.html